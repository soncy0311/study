{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c78cd5f-02b4-4b47-a97e-95e5d77c1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb229a0-121c-4427-9c04-ff1b2d7aa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc1ea41-fff7-40b6-a438-e396853d6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2022\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e40717-872b-4899-a6b1-551db882ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/USER/data002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab1be60-8f7d-433f-ab49-e4a840cbe0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1700120f-1811-4508-ad0c-550d87ccc8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200101</td>\n",
       "      <td>0</td>\n",
       "      <td>83247</td>\n",
       "      <td>19128</td>\n",
       "      <td>2611</td>\n",
       "      <td>5161</td>\n",
       "      <td>1588</td>\n",
       "      <td>892</td>\n",
       "      <td>32263</td>\n",
       "      <td>1636</td>\n",
       "      <td>...</td>\n",
       "      <td>1311</td>\n",
       "      <td>3482</td>\n",
       "      <td>11299</td>\n",
       "      <td>7072</td>\n",
       "      <td>1176</td>\n",
       "      <td>3810</td>\n",
       "      <td>748</td>\n",
       "      <td>3920</td>\n",
       "      <td>2133</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200101</td>\n",
       "      <td>1</td>\n",
       "      <td>89309</td>\n",
       "      <td>19027</td>\n",
       "      <td>3337</td>\n",
       "      <td>5502</td>\n",
       "      <td>1650</td>\n",
       "      <td>1043</td>\n",
       "      <td>35609</td>\n",
       "      <td>1644</td>\n",
       "      <td>...</td>\n",
       "      <td>1162</td>\n",
       "      <td>3849</td>\n",
       "      <td>13180</td>\n",
       "      <td>8771</td>\n",
       "      <td>1283</td>\n",
       "      <td>3763</td>\n",
       "      <td>782</td>\n",
       "      <td>3483</td>\n",
       "      <td>2057</td>\n",
       "      <td>4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200101</td>\n",
       "      <td>2</td>\n",
       "      <td>66611</td>\n",
       "      <td>14710</td>\n",
       "      <td>2970</td>\n",
       "      <td>4631</td>\n",
       "      <td>1044</td>\n",
       "      <td>921</td>\n",
       "      <td>26821</td>\n",
       "      <td>1104</td>\n",
       "      <td>...</td>\n",
       "      <td>768</td>\n",
       "      <td>2299</td>\n",
       "      <td>7986</td>\n",
       "      <td>5426</td>\n",
       "      <td>1536</td>\n",
       "      <td>3229</td>\n",
       "      <td>491</td>\n",
       "      <td>2634</td>\n",
       "      <td>1526</td>\n",
       "      <td>3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200101</td>\n",
       "      <td>3</td>\n",
       "      <td>53290</td>\n",
       "      <td>13753</td>\n",
       "      <td>2270</td>\n",
       "      <td>4242</td>\n",
       "      <td>1021</td>\n",
       "      <td>790</td>\n",
       "      <td>21322</td>\n",
       "      <td>909</td>\n",
       "      <td>...</td>\n",
       "      <td>632</td>\n",
       "      <td>1716</td>\n",
       "      <td>5703</td>\n",
       "      <td>3156</td>\n",
       "      <td>1104</td>\n",
       "      <td>2882</td>\n",
       "      <td>431</td>\n",
       "      <td>2488</td>\n",
       "      <td>1268</td>\n",
       "      <td>3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200101</td>\n",
       "      <td>4</td>\n",
       "      <td>52095</td>\n",
       "      <td>17615</td>\n",
       "      <td>2406</td>\n",
       "      <td>3689</td>\n",
       "      <td>1840</td>\n",
       "      <td>922</td>\n",
       "      <td>22711</td>\n",
       "      <td>1354</td>\n",
       "      <td>...</td>\n",
       "      <td>875</td>\n",
       "      <td>2421</td>\n",
       "      <td>5816</td>\n",
       "      <td>2933</td>\n",
       "      <td>1206</td>\n",
       "      <td>2433</td>\n",
       "      <td>499</td>\n",
       "      <td>2952</td>\n",
       "      <td>1927</td>\n",
       "      <td>5608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         날짜  시간     10    100   101   120   121   140    150   160  ...  1020  \\\n",
       "0  20200101   0  83247  19128  2611  5161  1588   892  32263  1636  ...  1311   \n",
       "1  20200101   1  89309  19027  3337  5502  1650  1043  35609  1644  ...  1162   \n",
       "2  20200101   2  66611  14710  2970  4631  1044   921  26821  1104  ...   768   \n",
       "3  20200101   3  53290  13753  2270  4242  1021   790  21322   909  ...   632   \n",
       "4  20200101   4  52095  17615  2406  3689  1840   922  22711  1354  ...   875   \n",
       "\n",
       "   1040   1100  1200  1510  2510  3000  4510  5510  6000  \n",
       "0  3482  11299  7072  1176  3810   748  3920  2133  3799  \n",
       "1  3849  13180  8771  1283  3763   782  3483  2057  4010  \n",
       "2  2299   7986  5426  1536  3229   491  2634  1526  3388  \n",
       "3  1716   5703  3156  1104  2882   431  2488  1268  3686  \n",
       "4  2421   5816  2933  1206  2433   499  2952  1927  5608  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec8fe57-8167-4b9a-a0e9-7d24c019f6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df[df.columns.values[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bc8a7943-3d60-4244-bc35-60fba4635c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['날짜']!=20200229][df['날짜']!=20200330])/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a7a64-b25f-44d1-b2cc-7ddcf4800b1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "##### 20200229 & 20200330 제거 후 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ffe8c646-856b-458e-bb38-554d1f75f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset) :\n",
    "    def __init__(self, data_dir, mode, seq_len, scaler) :\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.seq_len = seq_len*24\n",
    "        \n",
    "        df_path = os.path.join(self.data_dir, mode+'.csv')\n",
    "        df = pd.read_csv(df_path)\n",
    "        df_col = df.columns.values\n",
    "        df_scale = scaler.transform(df[df_col[2:]])\n",
    "        df[df_col[2:]] = df_scale\n",
    "        \n",
    "        if mode == 'train' :\n",
    "            df_train = df[df['날짜']!=20200229][df['날짜']!=20200330]\n",
    "\n",
    "            self.input_data = []\n",
    "            self.output_data = []\n",
    "\n",
    "            for t in range(0,len(df_train)-self.seq_len,24) :\n",
    "                temp_input_data = []\n",
    "                temp_output_data = []\n",
    "                for col in df_col[2:] :\n",
    "                    road = df_train[col].tolist()\n",
    "                    temp_input = [float(i) for i in road[t: t+self.seq_len]]\n",
    "                    temp_output = [float(j) for j in road[t+self.seq_len:t+2*self.seq_len]]\n",
    "                    temp_input_data.append(temp_input)\n",
    "                    temp_output_data.append(temp_output)\n",
    "                self.input_data.append(temp_input_data)\n",
    "                self.output_data.append(temp_output_data)\n",
    "                \n",
    "        elif mode == 'valid' :\n",
    "\n",
    "            self.input_data = []\n",
    "            self.output_data = []\n",
    "\n",
    "            temp_input_data = []\n",
    "            temp_output_data = []\n",
    "            for col in df_col[2:] :\n",
    "                road = df[col].tolist()\n",
    "                temp_input = [float(i) for i in road[:self.seq_len]]\n",
    "                temp_output = road[self.seq_len:self.seq_len*2]\n",
    "                temp_input_data.append(temp_input)\n",
    "                temp_output_data.append(temp_output)\n",
    "            self.input_data.append(temp_input_data)\n",
    "            self.output_data.append(temp_output_data)\n",
    "            \n",
    "        elif mode == 'test' :\n",
    "            \n",
    "            self.input_data = []\n",
    "\n",
    "            \n",
    "            temp_input_data = []\n",
    "            for col in df_col[2:] :\n",
    "                road = df[col].tolist()\n",
    "                temp_input = [float(i) for i in road[:self.seq_len]]\n",
    "                temp_input_data.append(temp_input)\n",
    "            self.input_data.append(temp_input_data)\n",
    "            \n",
    "    def __getitem__(self, index) :\n",
    "        day = index // 35\n",
    "        col = index % 35\n",
    "        \n",
    "        if self.mode == 'test' :\n",
    "            x = torch.tensor(self.input_data[day][col])\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        x = torch.tensor(self.input_data[day][col])\n",
    "        label = torch.tensor(self.output_data[day][col])\n",
    "        if label.shape[0] != 168:\n",
    "            print('day', 'co', day, col)\n",
    "        return x, label\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.input_data)*35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47c15bd-f69e-44e7-92b0-baaa8c6a9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBeats(nn.Module) :\n",
    "    def __init__(self, input_size, hidden_dim, output_size, num_layers=4, batch_size=64, bidirectional=False, dropout=0.3, batch_first=True) :\n",
    "        super(NBeats, self).__init__()\n",
    "        self.n_direction = 2 if bidirectional else 1\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.rnn1 = nn.LSTM(input_size = self.input_size,\n",
    "                            hidden_size = self.hidden_dim,\n",
    "                            num_layers = self.num_layers,\n",
    "                            dropout = dropout,\n",
    "                            bias = True,\n",
    "                            batch_first = self.batch_first,\n",
    "                            bidirectional = bidirectional)\n",
    "        self.rnn2 = nn.LSTM(input_size = self.hidden_dim,\n",
    "                            hidden_size = self.hidden_dim,\n",
    "                            num_layers = self.num_layers,\n",
    "                            dropout = dropout,\n",
    "                            bias = True,\n",
    "                            batch_first = self.batch_first,\n",
    "                            bidirectional = bidirectional)\n",
    "\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "            \n",
    "        self.out = nn.Linear(self.hidden_dim*self.n_direction, self.output_size)\n",
    "        \n",
    "        self.h_in = nn.Parameter(torch.zeros(num_layers, 1, hidden_dim, requires_grad=True)).to(device)\n",
    "        self.c_in = nn.Parameter(torch.zeros(num_layers, 1, hidden_dim, requires_grad=True)).to(device)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        h_in = self.h_in.expand(self.h_in.shape[0], x.shape[0], self.h_in.shape[2])\n",
    "        c_in = self.c_in.expand(self.c_in.shape[0], x.shape[0], self.c_in.shape[2])\n",
    "        \n",
    "        output, (h1, c1) = self.rnn1(x, (h_in.contiguous(), c_in.contiguous()))\n",
    "        output = self.activation(output)\n",
    "\n",
    "        output, (h2, c2) = self.rnn2(output, (h1, c1))\n",
    "        output = self.activation(output)\n",
    "\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, (h2, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5ebdf2-bb57-46cc-a530-acf2686fb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBeats_RNN(nn.Module) :\n",
    "    def __init__(self, input_size, hidden_dim, output_size, mode='gru', num_layers=4, batch_size=64, bidirectional=False, dropout=0.3, batch_first=True) :\n",
    "        super(NBeats, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.n_direction = 2 if bidirectional else 1\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        if self.mode == 'gru' :\n",
    "            self.rnn1 = nn.GRU(input_size = self.input_size,\n",
    "                               hidden_size = self.hidden_dim,\n",
    "                               num_layers = self.num_layers,\n",
    "                               dropout = dropout,\n",
    "                               bias = True,\n",
    "                               batch_first = self.batch_first,\n",
    "                               bidirectional = bidirectional)\n",
    "            self.rnn2 = nn.GRU(input_size = self.hidden_dim,\n",
    "                               hidden_size = self.hidden_dim,\n",
    "                               num_layers = self.num_layers,\n",
    "                               dropout = dropout,\n",
    "                               bias = True,\n",
    "                               batch_first = self.batch_first,\n",
    "                               bidirectional = bidirectional)\n",
    "        else :\n",
    "            self.rnn1 = nn.RNN(input_size = self.input_size,\n",
    "                               hidden_size = self.hidden_dim,\n",
    "                               num_layers = self.num_layers,\n",
    "                               dropout = dropout,\n",
    "                               bias = True,\n",
    "                               batch_first = self.batch_first,\n",
    "                               bidirectional = bidirectional)\n",
    "            self.rnn2 = nn.RNN(input_size = self.hidden_dim,\n",
    "                               hidden_size = self.hidden_dim,\n",
    "                               num_layers = self.num_layers,\n",
    "                               dropout = dropout,\n",
    "                               bias = True,\n",
    "                               batch_first = self.batch_first,\n",
    "                               bidirectional = bidirectional)\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "            \n",
    "        self.out = nn.Linear(self.hidden_dim*self.n_direction, self.output_size)\n",
    "        \n",
    "        self.h_in = nn.Parameter(torch.zeros(num_layers, 1, hidden_dim, requires_grad=True)).to(device)\n",
    "        \n",
    "    def forward(self, x, h0) :\n",
    "        h_in = self.h_in.expand(self.h_in.shape[0], x.shape[0], self.h_in.shape[2])\n",
    "        \n",
    "        output, h1 = self.rnn1(x, h0)\n",
    "        output = self.activation(output)\n",
    "\n",
    "        output, h2 = self.rnn2(output, h1)\n",
    "        output = self.activation(output)\n",
    "\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cf53df6-21e8-47bf-bdc2-ed759e0eb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 파일과 모델 가중치 파일 저장을 위해 log 디렉토리 생성. 중요한 파일이 덮어씌워지지 않도록 주의\n",
    "os.makedirs('log', exist_ok=True)      # log 폴더 생성, 이미 생성되었을 시 추가로 생성하지 않도록 exist_ok=True\n",
    "\n",
    "\n",
    "def save_model(model_name, model, optimizer):      # 모델 가중치 파일 저장 함수\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler' : scheduler.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join('log', model_name + '.pt'))\n",
    "    print('model saved\\n')\n",
    "\n",
    "\n",
    "def load_model(model_name, model, optimizer=None):      # 모델 가중치 파일 로드 함수\n",
    "    state = torch.load(os.path.join(model_name))\n",
    "    model.load_state_dict(state['model'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8817cfd-ea94-433b-9e03-82cf5dc86b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "seq_len = 7\n",
    "\n",
    "input_size = 1\n",
    "hidden_dim = 1024\n",
    "output_size = seq_len*24\n",
    "batch_size = 64\n",
    "num_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e4bb0c6-6e56-4dac-a1bf-b8badd8420da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(data_dir=data_dir, mode='train', scaler=scaler, seq_len=seq_len)\n",
    "valid_dataset = CustomDataset(data_dir=data_dir, mode='valid', scaler=scaler, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ccda46d6-b854-4aa4-83de-5786f9c4d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a863f58a-4ef0-484c-8abd-3b39f107116d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['날짜']!=20200229][df['날짜']!=20200330])/24 - 4515/35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0b258439-82a0-44c0-8a4f-177426a44d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4515 4515 4515\n"
     ]
    }
   ],
   "source": [
    "length = 0\n",
    "for i in train_dataset :\n",
    "    length += 1\n",
    "    \n",
    "print(length,len(train_dataset),129*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9274960a-3161-4065-b62e-7c40e7335acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>20200206</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>20200515</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            날짜  시간  10  100  101  120  121  140  150  160  ...  1020  1040  \\\n",
       "882   20200206  18   0   86    0    1    0    0    4    0  ...    49     0   \n",
       "3212  20200515   5   0    0    0    0    0    0    0    0  ...     0     0   \n",
       "\n",
       "      1100  1200  1510  2510  3000  4510  5510  6000  \n",
       "882      0     4     0     0     0    35     0     0  \n",
       "3212     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[882,3212]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c879ad12-4e47-47b3-9dd8-659d32e19fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset : 4515, Valid Dataset : 35\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Dataset : {len(train_dataset)}, Valid Dataset : {len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3416e120-6975-48ad-a3a5-ac39639a4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 23\n",
      "123 12\n",
      "125 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [168] at entry 0 and [24] at entry 26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8656/3593190873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [168] at entry 0 and [24] at entry 26"
     ]
    }
   ],
   "source": [
    "for sample in train_dataloader :\n",
    "    input_data, output_data = sample\n",
    "    print(input_data.shape,output_data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11b1caa5-a34f-4058-9b92-06b27fade935",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBeats(input_size=input_size, hidden_dim=hidden_dim, output_size=output_size, batch_size=batch_size, num_layers=num_layers).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler =  torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=1e-4, epochs=num_epochs, steps_per_epoch=len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8425187-6214-4dc9-ab1a-c0845efbfaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBeats(\n",
      "  (rnn1): LSTM(1, 1024, num_layers=4, batch_first=True, dropout=0.3)\n",
      "  (rnn2): LSTM(1024, 1024, num_layers=4, batch_first=True, dropout=0.3)\n",
      "  (activation): LeakyReLU(negative_slope=0.2)\n",
      "  (out): Linear(in_features=1024, out_features=168, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8a9aa8d-453a-41d3-9883-6ca2942aa0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.9651177128156027\n",
      "\n",
      "Valid Epoch:  1 | Loss: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 1/50 [00:07<06:25,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9445599516232809\n",
      "\n",
      "Valid Epoch:  2 | Loss: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 2/50 [00:15<06:18,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9972164233525594\n",
      "\n",
      "Valid Epoch:  3 | Loss: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 3/50 [00:23<06:10,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9823345343271891\n",
      "\n",
      "Valid Epoch:  4 | Loss: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% 4/50 [00:31<06:03,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9283886154492696\n",
      "\n",
      "Valid Epoch:  5 | Loss: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 5/50 [00:39<05:48,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9618307749430338\n",
      "\n",
      "Valid Epoch:  6 | Loss: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12% 6/50 [00:47<05:44,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9549042383829752\n",
      "\n",
      "Valid Epoch:  7 | Loss: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% 7/50 [00:55<05:38,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.8882760802904764\n",
      "\n",
      "Valid Epoch:  8 | Loss: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 8/50 [01:02<05:31,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 1.0100247065226238\n",
      "\n",
      "Valid Epoch:  9 | Loss: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% 9/50 [01:10<05:24,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9252643386522929\n",
      "\n",
      "Valid Epoch: 10 | Loss: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 10/50 [01:18<05:06,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9004679918289185\n",
      "\n",
      "Valid Epoch: 11 | Loss: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 11/50 [01:25<05:02,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.9171095689137777\n",
      "\n",
      "Valid Epoch: 12 | Loss: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 12/50 [01:33<04:57,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.8677790363629659\n",
      "\n",
      "Valid Epoch: 13 | Loss: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% 13/50 [01:41<04:50,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.8456388711929321\n",
      "\n",
      "Valid Epoch: 14 | Loss: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28% 14/50 [01:50<04:45,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 15/50 [01:52<03:45,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.8788470427195231\n",
      "\n",
      "Valid Epoch: 15 | Loss: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% 16/50 [01:56<03:04,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.8361051877339681\n",
      "\n",
      "Valid Epoch: 16 | Loss: 0.87\n",
      "Train Epoch_Loss: 0.8226982156435648\n",
      "\n",
      "Valid Epoch: 17 | Loss: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34% 17/50 [02:04<03:25,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 18/50 [02:07<02:48,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.8399436672528585\n",
      "\n",
      "Valid Epoch: 18 | Loss: 0.88\n",
      "Train Epoch_Loss: 0.8601533969243368\n",
      "\n",
      "Valid Epoch: 19 | Loss: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 19/50 [02:15<03:09,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.8190958698590597\n",
      "\n",
      "Valid Epoch: 20 | Loss: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 20/50 [02:23<03:21,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.8202887972195944\n",
      "\n",
      "Valid Epoch: 21 | Loss: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 21/50 [02:31<03:26,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.714767336845398\n",
      "\n",
      "Valid Epoch: 22 | Loss: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44% 22/50 [02:39<03:27,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.45529939730962116\n",
      "\n",
      "Valid Epoch: 23 | Loss: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46% 23/50 [02:47<03:25,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n",
      "Train Epoch_Loss: 0.3805573880672455\n",
      "\n",
      "Valid Epoch: 24 | Loss: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48% 24/50 [02:55<03:21,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 25/50 [02:58<02:38,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.23851224283377329\n",
      "\n",
      "Valid Epoch: 25 | Loss: 0.20\n",
      "Train Epoch_Loss: 0.2268537680308024\n",
      "\n",
      "Valid Epoch: 26 | Loss: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52% 26/50 [03:06<02:44,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% 27/50 [03:09<02:11,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.16661937783161798\n",
      "\n",
      "Valid Epoch: 27 | Loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% 28/50 [03:13<01:48,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.17351031800111136\n",
      "\n",
      "Valid Epoch: 28 | Loss: 0.16\n",
      "Train Epoch_Loss: 0.16621138652165732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58% 29/50 [03:16<01:32,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Epoch: 29 | Loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 30/50 [03:19<01:20,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.15412770211696625\n",
      "\n",
      "Valid Epoch: 30 | Loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62% 31/50 [03:22<01:11,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.21335641543070474\n",
      "\n",
      "Valid Epoch: 31 | Loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% 32/50 [03:25<01:04,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.1567138135433197\n",
      "\n",
      "Valid Epoch: 32 | Loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66% 33/50 [03:28<00:58,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.15352867543697357\n",
      "\n",
      "Valid Epoch: 33 | Loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68% 34/50 [03:31<00:53,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.1491810828447342\n",
      "\n",
      "Valid Epoch: 34 | Loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 35/50 [03:35<00:49,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.18025457859039307\n",
      "\n",
      "Valid Epoch: 35 | Loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72% 36/50 [03:38<00:45,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.1460054243604342\n",
      "\n",
      "Valid Epoch: 36 | Loss: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74% 37/50 [03:41<00:42,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.17049298683802286\n",
      "\n",
      "Valid Epoch: 37 | Loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76% 38/50 [03:44<00:38,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.180838813384374\n",
      "\n",
      "Valid Epoch: 38 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78% 39/50 [03:47<00:35,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.1836670239766439\n",
      "\n",
      "Valid Epoch: 39 | Loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 40/50 [03:50<00:32,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.13745117435852686\n",
      "\n",
      "Valid Epoch: 40 | Loss: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82% 41/50 [03:54<00:28,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.1350016916791598\n",
      "\n",
      "Valid Epoch: 41 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84% 42/50 [03:57<00:25,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.15905430912971497\n",
      "\n",
      "Valid Epoch: 42 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86% 43/50 [04:00<00:22,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.13504428416490555\n",
      "\n",
      "Valid Epoch: 43 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88% 44/50 [04:03<00:19,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.13579114774862924\n",
      "\n",
      "Valid Epoch: 44 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 45/50 [04:06<00:15,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.14256412784258524\n",
      "\n",
      "Valid Epoch: 45 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92% 46/50 [04:10<00:12,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.13029038161039352\n",
      "\n",
      "Valid Epoch: 46 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94% 47/50 [04:13<00:09,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.13779561469952264\n",
      "\n",
      "Valid Epoch: 47 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96% 48/50 [04:16<00:06,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.17281142373879751\n",
      "\n",
      "Valid Epoch: 48 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% 49/50 [04:19<00:03,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.18293361365795135\n",
      "\n",
      "Valid Epoch: 49 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 50/50 [04:23<00:00,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch_Loss: 0.14350182811419168\n",
      "\n",
      "Valid Epoch: 50 | Loss: 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_batch_loss = []\n",
    "train_epoch_loss = []\n",
    "\n",
    "valid_epoch_loss = []\n",
    "valid_min_epoch_loss = np.inf\n",
    "for epoch in tqdm(range(num_epochs)) :\n",
    "    model.train()\n",
    "\n",
    "    for i, sample in enumerate(train_dataloader) :\n",
    "\n",
    "        input_data, output_data = sample\n",
    "\n",
    "        input_data = input_data.unsqueeze(2).to(device)\n",
    "        output_data = output_data.unsqueeze(2).to(device)\n",
    "\n",
    "        pred, (h_out, c_out) = model(input_data)\n",
    "        loss = criterion(pred, output_data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_batch_loss.append(loss.item())\n",
    "        train_epoch_loss.append(loss.item())\n",
    "\n",
    "        if i % 400 == 399:      # 400개의 batch마다 training Loss 출력\n",
    "            print('Train Epoch: {:2} | Batch: {:4} | Loss: {:1.2f}'.format(epoch+1, i+1, np.array(train_batch_loss).mean()))\n",
    "            train_batch_loss = []\n",
    "\n",
    "    print(f'Train Epoch_Loss: {np.array(train_epoch_loss).mean()}')\n",
    "    train_epoch_loss = []\n",
    "\n",
    "    model.eval()      # 모델을 eval mode로 전환. eval mode에서 적용되면 안되는 drop out 등이 적용되지 않게 하기 위함\n",
    "\n",
    "    with torch.no_grad():      # validation / test set에 대해서는 weight 및 bias의 update, 즉, gradient descent가 일어나지 않도록 no_grad()를 선언\n",
    "\n",
    "        for i, sample in enumerate(valid_dataloader):      # enumerate 함수를 통해 validate_dataloader에서 'batch의 index'와 'batch'를 순서대로 호출\n",
    "\n",
    "            input_data, output_data = sample      # validate_dataloader에서 불러온 sample은 [[날짜, 시간], [도로], [[input_data],[output_data]]]로 구성됨. validation에는 [[input_data], [output_data]]만 사용\n",
    "\n",
    "            input_data = input_data.unsqueeze(2).to(device)\n",
    "            output_data = output_data.unsqueeze(2).to(device)\n",
    "\n",
    "            pred, (h_in, c_in) = model(input_data)\n",
    "            loss = criterion(pred, output_data)\n",
    "            valid_epoch_loss.append(loss.item())\n",
    "\n",
    "        print('\\nValid Epoch: {:2} | Loss: {:1.2f}'.format(epoch+1, np.array(valid_epoch_loss).mean()))\n",
    "\n",
    "        if np.array(valid_epoch_loss).mean() < valid_min_epoch_loss:\n",
    "            save_model('nbeats_v001', model, optimizer)\n",
    "            valid_min_epoch_loss = np.array(valid_epoch_loss).mean()\n",
    "\n",
    "        valid_epoch_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51619943-eeb7-4f78-a118-913cfdac6bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2267, -1.4794, -1.5796, -1.5635, -1.2612, -0.3431,  0.6267,  1.0206,\n",
      "          0.7424,  0.5600,  0.6943,  0.7258,  0.5829,  0.5568,  0.6683,  0.7546,\n",
      "          0.5960,  0.7031,  0.6144,  0.0128, -0.3113, -0.4340, -0.7481, -1.1034,\n",
      "         -1.3319, -1.4832, -1.5597, -1.5476, -1.3988, -0.8801, -0.0803,  0.4733,\n",
      "          0.5977,  0.5413,  0.6624,  0.6525,  0.5293,  0.6534,  0.6787,  0.8033,\n",
      "          0.8950,  1.0185,  0.7473,  0.1111, -0.1745, -0.3250, -0.5926, -0.9449,\n",
      "         -1.2490, -1.4348, -1.5124, -1.5163, -1.3237, -0.6496,  0.2151,  0.7481,\n",
      "          0.7963,  0.7745,  0.8858,  0.8497,  0.8047,  0.7751,  0.8081,  0.8975,\n",
      "          1.0264,  1.2133,  0.8903,  0.1779, -0.1200, -0.2408, -0.5797, -0.8939,\n",
      "         -1.2127, -1.4307, -1.5251, -1.5112, -1.3321, -0.6978,  0.1535,  0.6991,\n",
      "          0.8203,  0.7404,  0.9182,  0.8872,  0.7465,  0.8051,  0.8417,  0.9513,\n",
      "          1.0337,  1.1850,  0.9802,  0.3604,  0.0785, -0.0921, -0.4629, -0.8650,\n",
      "         -1.2112, -1.4070, -1.5005, -1.5011, -1.3092, -0.7231,  0.0911,  0.6685,\n",
      "          0.7333,  0.6970,  0.9038,  0.9717,  0.9306,  1.0666,  1.2518,  1.4238,\n",
      "          1.5502,  1.7013,  1.5371,  1.1205,  0.7257,  0.4835, -0.1068, -0.6471,\n",
      "         -1.0792, -1.3539, -1.4849, -1.5093, -1.3532, -0.7982, -0.2197,  0.0870,\n",
      "          0.5395,  0.8965,  1.1490,  1.1746,  0.9772,  0.9959,  1.0956,  1.2382,\n",
      "          1.2415,  1.2562,  0.9216,  0.4905,  0.1861,  0.0520, -0.3779, -0.8819,\n",
      "         -1.2710, -1.5113, -1.6281, -1.6924, -1.6512, -1.3500, -1.0351, -0.8326,\n",
      "         -0.4968,  0.0469,  0.5776,  0.7631,  0.7559,  0.9665,  1.2325,  1.3438,\n",
      "          1.3556,  1.1395,  0.9160,  0.6768,  0.5602,  0.5942,  0.0416, -0.7221]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(output_data.squeeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a41038-533c-48dc-8c80-366cff5a833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join(data_dir,'sample_submission.csv')\n",
    "submission_table = pd.read_csv(submission_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab1218a6-a64c-490e-aea3-602afd49ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(data_dir=data_dir, mode='test', scaler=scaler, seq_len=seq_len)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48d48380-466a-4eba-8bb9-e0fd918c31d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "length = 0\n",
    "for sample in test_dataloader :\n",
    "    length += 1\n",
    "    \n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e33a37ba-7602-44a2-a4d3-627f4b3e7461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([168, 168])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sample in test_dataloader :\n",
    "        input_data = sample.unsqueeze(2).to(device)\n",
    "        pred, (h_out, c_out) = model(input_data)\n",
    "        print(pred.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd315a8-1495-414d-a35f-e00720aa19d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
